# @package _global_

# python run.py experiment=sr3_diffusion/unet_supernet

# specify here default configuration
defaults:
  - /engines/sr3_diffusion_infer@engines.tester
  - /loggers/wandb
  - override /datamodule: div2k/small
  - override /device: null
  - override /engines: sr3_diffusion_trainer
  - override /mode: experiment
  - override /loggers: tensorboard
  - override /model: sr3_diffusion/unet_attention_supernet

device: "cuda:6"

name: sr3_diffusion/unet_supernet
seed: 12345

loggers:
  tensorboard:
    handlers:
      train_output:
        log_handler:
          # log temperature state attribute
          state_attributes: ['temperature']
      arch_output:
        engines: ['arch_trainer']
        log_handler:
          _target_: ignite.contrib.handlers.tensorboard_logger.OutputHandler
          tag: arch
          metric_names: all
          # log temperature state attribute
          state_attributes: ['temperature']
          # include all return keys with 'loss' in them
          output_transform: ${eval:"lambda o:{k:v for k,v in o.items() if 'loss' in k}"}
        event:
          _target_: ignite.engine.events.Events.EPOCH_COMPLETED
          every: 1
      finetune_output:
        engines: ['finetune']
        log_handler:
          _target_: ignite.contrib.handlers.tensorboard_logger.OutputHandler
          tag: finetune
          metric_names: all
          # include all return keys with 'loss' in them
          output_transform: ${eval:"lambda o:{k:v for k,v in o.items() if 'loss' in k}"}
        event:
          _target_: ignite.engine.events.Events.EPOCH_COMPLETED
          every: 1

# reduce data loading and dataset size
datamodule:
  batch_size_train: 8
  batch_size_test: 8
  batch_size_validation: 8
  subset: "unknown_x2"
  patch_size: 128
  train_split: train
  test_split: validation[:50]
  validation_split: validation[50:]
  lr_upscaling: bicubic
  in_memory: True

# reduce epochs and variance schedule
# increase validation frequency
engine_run_order: ['trainer', 'finetune', 'tester']
engines:
  trainer:
    engine:
      max_epochs: 100
      # max_epochs: 1
      # don't add flops for trainning supernet, instead add it for arch. params
      metric_loss_weights: null
      beta_variance_schedule:
        _target_: torch.linspace
        start: 1e-6
        end: 1e-2
        steps: 2_000
      conditional: True
      optimizer:
        _target_: torch.optim.Adam
        lr: 3e-6
        _args_:
          - ${eval:"di['model'].supernet_parameters()"}
      loss_fn:
        _target_: torch.nn.L1Loss
        reduction: mean
    handlers:
      # validation trigger
      train_validator:
        handler: ${eval:"lambda:di['engines.validator'].run()"}
        event:
        - _target_: ignite.engine.events.Events.EPOCH_COMPLETED
          every: 100
        # - _target_: ignite.engine.events.Events.COMPLETED
        #   every: 1
      # supernet trigger
      train_supernet:
        handler: ${eval:"lambda:di['engines.arch_trainer'].run()"}
        event:
        - _target_: ignite.engine.events.Events.EPOCH_COMPLETED
          every: 1
      # update temperature
      temperature_fn:
        handler:
          _target_: src.handlers.supernet_temperature.SupernetGlobalTemperatureUpdate
          model: ${di:model}
          initial_value: 20.0
          update_fn:
            _target_: src.handlers.supernet_temperature.update_wrapper
            _args_:
              - _target_: src.handlers.supernet_temperature.create_tanh_decay
                max: 20.0
                min: 0.08
                width: 5_000
        event:
          _target_: ignite.engine.events.Events.ITERATION_COMPLETED
          every: 1
      # handler to init. model weights
      weight_init:
        handler:
          _target_: src.handlers.weight_init.ModelWeightHandler
        kwargs:
          model: ${di:model}
          kind: orthogonal
      # log subnet measurement metrics
      subnet_metrics:
        handler:
          _target_: src.handlers.subnet_measurement.SubnetMeasurement
          model: ${di:model}
          metric_to_state_names:
            flops: "subnet/flops"
            latency: "subnet/latency"
        event:
          _target_: ignite.engine.events.Events.EPOCH_COMPLETED
          every: 1
      # log train images
      log_images:
        handler:
          _target_: src.handlers.log_output_images.LogOutputImages
          tag: train_images
          metric_names: ['x_original', 'y_original', 'y_noisy']
          n_images: 4
          orientation: vertical
        kwargs:
          logger: ${di:"loggers.tensorboard"}
          trigger_event:
            _target_: ignite.engine.events.Events.EPOCH_STARTED
            every: 50
  # supernet engine
  arch_trainer:
    engine:
      _target_: src.engines.sr3_diffusion.SR3DiffusionTrainingEngine
      # arch data is 50 while train data is 700
      # so we run for 700/50 epochs per 1 train epoch
      # but we don't have any time so we run for only 1 epoch
      max_epochs: ${engines.trainer.engine.max_epochs}
      # metric weights make metrics in ~0.1 scale
      metric_loss_weights:
        flops: 5e-17
        latency: 5e-5
      # train supernet params on validation data
      data: ${di:datamodule_validation_loader}
      denoise_model: ${di:model}
      optimizer:
        _target_: torch.optim.Adam
        lr: 3e-5
        _args_:
          - ${eval:"di['model'].architecture_parameters()"}
      conditional: True
      beta_variance_schedule: ${engines.trainer.engine.beta_variance_schedule}
      loss_fn:
        _target_: torch.nn.L1Loss
        reduction: mean
    handlers:
      # disable logging
      warn_only_log:
        handler: ${eval:"lambda e:e.logger.setLevel(30)"}
        event:
          _target_: ignite.engine.events.Events.STARTED
          every: 1
      # run for only 1 epoch, then pause
      one_epoch:
        handler: ${eval:"lambda e:e.terminate()"}
        event:
          _target_: ignite.engine.events.Events.EPOCH_COMPLETED
          every: 1
        kwargs:
          e: ${di:engines.arch_trainer}
      # progress bar
      tqdm_progress_bar:
        handler:
          _target_: ignite.contrib.handlers.tqdm_logger.ProgressBar
        kwargs:
          metric_names: all
  # validation engine
  validator:
    engine:
      _target_: src.engines.sr3_diffusion.SubnetSR3DiffusionInferenceEngine
      max_epochs: ${engines.trainer.engine.max_epochs}
      data: ${di:datamodule_validation_loader}
      denoise_model: ${di:model}
      steps_to_record: [1999, 1500, 1000, 250, 500, 0]
      beta_variance_schedule: ${engines.trainer.engine.beta_variance_schedule}
    handlers:
      # disable logging
      warn_only_log:
        handler: ${eval:"lambda e:e.logger.setLevel(30)"}
        event:
          _target_: ignite.engine.events.Events.STARTED
          every: 1
      # validate for only 1 epoch, then pause
      one_epoch:
        handler: ${eval:"lambda e:e.terminate()"}
        event:
          _target_: ignite.engine.events.Events.EPOCH_COMPLETED
          every: 1
        kwargs:
          e: ${di:engines.validator}
      # add handler to log validation images
      log_images:
        handler:
          _target_: src.handlers.log_output_images.LogOutputImages
          tag: validation_images
          metric_names: [1999, 1500, 1000, 250, 500, 0, 'lr', 'hr']
          n_images: 4
          orientation: vertical
        kwargs:
          logger: ${di:"loggers.tensorboard"}
  # finetune engine
  finetune:
    engine:
      _target_: src.engines.sr3_diffusion.SR3DiffusionTrainingEngine
      max_epochs: ${engines.trainer.engine.max_epochs}
      # max_epochs: 1
      data: ${di:datamodule_train_loader}
      metric_loss_weights: null
      denoise_model: ${di:model}
      beta_variance_schedule: ${engines.trainer.engine.beta_variance_schedule}
      conditional: True
      optimizer:
        _target_: torch.optim.Adam
        lr: 1e-6
        _args_:
          - ${eval:"di['model'].supernet_parameters()"}
      loss_fn:
        _target_: torch.nn.L1Loss
        reduction: mean
    handlers:
      # mask subnet
      mask_subnet:
        handler: ${eval:"lambda:di['model'].apply_subnet_mask()"}
        event:
          _target_: ignite.engine.events.Events.STARTED
          every: 1
      # unmask subnet
      unmask_subnet:
        handler: ${eval:"lambda:di['model'].pop_subnet_mask()"}
        event:
          _target_: ignite.engine.events.Events.COMPLETED
          every: 1
      # validation trigger
      validator_trigger:
        handler: ${eval:"lambda:di['engines.validator'].run()"}
        event:
        - _target_: ignite.engine.events.Events.COMPLETED
          every: 1
      # log subnet measurement metrics
      subnet_metrics:
        handler:
          _target_: src.handlers.subnet_measurement.SubnetMeasurement
          model: ${di:model}
          metric_to_state_names:
            flops: "subnet/flops"
            latency: "subnet/latency"
        event:
          _target_: ignite.engine.events.Events.STARTED
          once: 1
      # log train images
      log_images:
        handler:
          _target_: src.handlers.log_output_images.LogOutputImages
          tag: finetune_images
          metric_names: ['x_original', 'y_original', 'y_noisy']
          n_images: 4
          orientation: vertical
        kwargs:
          logger: ${di:"loggers.tensorboard"}
          trigger_event:
            _target_: ignite.engine.events.Events.EPOCH_STARTED
            every: 100
      # progress bar
      tqdm_progress_bar:
        handler:
          _target_: ignite.contrib.handlers.tqdm_logger.ProgressBar
        kwargs:
          metric_names: all
  # testing engine
  tester:
    engine:
      _target_: src.engines.sr3_diffusion.SubnetSR3DiffusionInferenceEngine
      max_epochs: 1
      steps_to_record: [1999, 1500, 1000, 250, 500, 0]
      beta_variance_schedule: ${engines.trainer.engine.beta_variance_schedule}
    handlers:
      # model checkpoint
      checkpoint:
        handler:
          _target_: ignite.handlers.checkpoint.ModelCheckpoint
          dirname: ckpt
          filename_prefix: test_model
          score_function: ${eval:"lambda e:1.0"}
          n_saved: 1
          create_dir: True
        args:
          - model: ${eval:"di['model']"}
        event:
          _target_: ignite.engine.events.Events.STARTED
          every: 1
      # add handler to log validation images
      log_images:
        handler:
          _target_: src.handlers.log_output_images.LogOutputImages
          tag: test_images
          metric_names: [1999, 1500, 1000, 250, 500, 0, 'lr', 'hr']
          n_images: 20
          orientation: vertical
        kwargs:
          logger: ${di:"loggers.tensorboard"}